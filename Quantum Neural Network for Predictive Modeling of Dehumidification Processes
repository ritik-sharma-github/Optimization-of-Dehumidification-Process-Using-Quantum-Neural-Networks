
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

df=pd.read_excel("/content/Temperature Dataset.xlsx")

df

# Display summary statistics for the DataFrame
print("\nSummary statistics:")
df.describe()

# Check for missing values
print("\nMissing values:")
print(df.isnull().sum())

# Display the column names
print("\nColumn names:")
print(df.columns)

# Basic data types info
print("\nData types:")
print(df.dtypes)

# Convert specific columns from int to float
columns_to_convert = ['tc (s)']
df[columns_to_convert] = df[columns_to_convert].astype(float)

# Check the updated data types
print(df.dtypes)

import seaborn as sns

# Compute the correlation matrix
correlation_matrix = df.corr()

# Display the correlation matrix
print("\nCorrelation matrix:")
print(correlation_matrix)

# Plot the correlation matrix
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Correlation Matrix')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler


# Define features and target variables
X = df[[ 'Twi (℃)', 'Tai (℃)', 'Wai (g/kg)']]
y = df[['Two (℃)']]

# Normalize the data
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X_scaled = scaler_X.fit_transform(X)
y_scaled = scaler_y.fit_transform(y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)

import pennylane as qml
from pennylane import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

# Set up the quantum device
n_qubits = 3  # Number of qubits matching the number of features
dev = qml.device('default.qubit', wires=n_qubits)

# Define a quantum layer
@qml.qnode(dev, interface='tf')
def quantum_layer(inputs, weights):
    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits)) # AngleEmbedding applies an n_qubit parameterized rotation to the n wires
    qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))
    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]

weight_shapes = {'weights': (3, n_qubits, 3)}

# Define a custom RMSE loss function
def rmse(y_true, y_pred):
    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))

# Build the hybrid QNN model
def create_hybrid_model():
    model = Sequential()
    model.add(tf.keras.layers.Input(shape=(X_train.shape[1],)))
    model.add(Dense(n_qubits, activation='relu')) # Adjust the number of neurons in the dense layer to match n_qubits
    model.add(qml.qnn.KerasLayer(quantum_layer, weight_shapes, output_dim=n_qubits)) # Output dimension should match the number of qubits
    model.add(Dense(1))  # Output layer for predicting 'Two (℃)'
    return model

# Compile the model with the custom RMSE loss function
model = create_hybrid_model()
model.compile(optimizer=Adam(learning_rate=0.01), loss=rmse)

# Train the model
history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test))

# Evaluate the model
test_loss = model.evaluate(X_test, y_test, batch_size=64)
print(f"Test RMSE: {test_loss}")

# Predict and inverse transform the results
y_pred_scaled = model.predict(X_test)
y_pred = scaler_y.inverse_transform(y_pred_scaled)
y_test = scaler_y.inverse_transform(y_test)

# Compare actual and predicted values
comparison = pd.DataFrame({'Actual Two (℃)': y_test[:, 0], 'Predicted Two (℃)': y_pred[:, 0],})
print(comparison)

import numpy as np
import pandas as pd

# Actual values
actual_values = np.array([
    [27.5],
    [25.0],
    [25.7],
    [28.5],
    [27.0],
    [26.2],
    [26.5],
    [23.0],
    [26.4],
    [32.5],
    [28.5],
    [22.0]
])

# Predicted values (updated)
predicted_values = np.array([
    [28.714415],
    [22.782198],
    [26.672234],
    [27.867586],
    [27.946274],
    [27.370394],
    [28.279718],
    [22.533247],
    [26.173168],
    [31.004097],
    [28.773884],
    [21.190441]
])

# Compute error percentage
error_percentage = np.abs((actual_values - predicted_values) / actual_values) * 100

# Convert to DataFrame for better readability
error_df = pd.DataFrame(error_percentage, columns=['Two (℃) Error (%)'])

print(error_df)

import matplotlib.pyplot as plt
import numpy as np

# Actual values
y_test = np.array([
    [27.5],
    [25.0],
    [25.7],
    [28.5],
    [27.0],
    [26.2],
    [26.5],
    [23.0],
    [26.4],
    [32.5],
    [28.5],
    [22.0]
])

# Predicted values
y_pred = np.array([
    [28.714415],
    [22.782198],
    [26.672234],
    [27.867586],
    [27.946274],
    [27.370394],
    [28.279718],
    [22.533247],
    [26.173168],
    [31.004097],
    [28.773884],
    [21.190441]
])

# Plot for Two (℃)
plt.figure(figsize=(12, 6))
plt.plot(y_test[:, 0], label='Actual Two (℃)')
plt.plot(y_pred[:, 0], label='Predicted Two (℃)', linestyle='--')
plt.xlabel('Sample')
plt.ylabel('Two (℃)')
plt.title('Actual vs Predicted - Two (℃)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss (RMSE)')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.show()

from sklearn.metrics import mean_absolute_error, r2_score

# Calculate MAE and R2 Score
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae}")
print(f"R2 Score: {r2}")

import matplotlib.pyplot as plt

# Residual errors (errors between actual and predicted values)
residuals = y_test - y_pred
residuals

# Plot for Two (℃)
plt.figure(figsize=(12, 6))
plt.plot(residuals[:, 0], label='Residuals Two (℃)')
plt.xlabel('Sample')
plt.ylabel('Residual (℃)')
plt.title('Residuals - Two (℃)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

residuals

plt.figure(figsize=(10, 6))
plt.plot(y_test, label='Actual')
plt.plot(y_pred, label='Predicted')
plt.title('Actual vs Predicted')
plt.xlabel('Sample Index')
plt.ylabel('Value')
plt.legend()
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Define your data
data = {
    'Twi (℃)': [25, 25, 30, 20, 30, 20, 30, 25],
    'Tai (℃)': [30, 27, 35, 26, 30, 26, 33, 32],
    'Wai (g/kg)': [21.5, 18, 23.2, 13, 21.5, 18, 12.5, 23],
    'Two (℃)': [27.5, 25.95, 32, 22, 32, 25, 34, 27]
}

df = pd.DataFrame(data)

# Define features and target variables
X = df[['Twi (℃)', 'Tai (℃)', 'Wai (g/kg)']]
y = df[['Two (℃)']]

# Normalize the data
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X_scaled = scaler_X.fit_transform(X)
y_scaled = scaler_y.fit_transform(y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)

# Define the custom equation layer
class CustomEquationLayer(Layer):
    def __init__(self, a=1.0, b=0.0, **kwargs):
        super(CustomEquationLayer, self).__init__(**kwargs)
        self.a = a
        self.b = b

    def build(self, input_shape):
        self.a = self.add_weight(name='a', shape=[], initializer='uniform', trainable=True)
        self.b = self.add_weight(name='b', shape=[], initializer='zeros', trainable=True)
        super(CustomEquationLayer, self).build(input_shape)

    def call(self, inputs):
        return self.a * inputs + self.b

    def get_config(self):
        config = super(CustomEquationLayer, self).get_config()
        config.update({'a': self.a, 'b': self.b})
        return config

# Build the model
def create_model():
    model = Sequential()
    model.add(tf.keras.layers.Input(shape=(X_train.shape[1],)))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(64, activation='relu'))
    model.add(CustomEquationLayer())  # Custom layer with your equation
    model.add(Dense(1))  # Output layer for predicting 'Two (℃)'
    return model

# Compile the model
model = create_model()
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
history = model.fit(X_train, y_train, epochs=100, batch_size=1, validation_data=(X_test, y_test))

# Evaluate the model
test_loss = model.evaluate(X_test, y_test, batch_size=1)
print(f"Test Loss (MSE): {test_loss}")

# Predict and inverse transform the results
y_pred_scaled = model.predict(X_test)
y_pred = scaler_y.inverse_transform(y_pred_scaled)
y_test = scaler_y.inverse_transform(y_test)

# Compare actual and predicted values
comparison = pd.DataFrame({'Actual Two (℃)': y_test[:, 0], 'Predicted Two (℃)': y_pred[:, 0]})
print(comparison)
